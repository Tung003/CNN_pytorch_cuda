{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1c7BS6asaH3U552lPGTl2BpbfZM7x1KZr",
      "authorship_tag": "ABX9TyM5oLAME+JlX0m69LUTgXxx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tung003/CNN_pytorch_cuda/blob/master/CNN_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fysLxKCWyJ82",
        "outputId": "c8a8a7ed-5d37-4c41-caa6-497ba4e40283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m894.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.5.1+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install pillow\n",
        "!pip install opencv-python\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms,datasets\n",
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform=transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,),(0.5,))])\n",
        "\n",
        "train_dataset=datasets.CIFAR10(root='/content/drive/MyDrive/Colab Notebooks/celeba/data',\n",
        "                               train=True,download=False,transform=transform)\n",
        "test_dataset=datasets.CIFAR10(root='/content/drive/MyDrive/Colab Notebooks/celeba/data',\n",
        "                              train=False,download=False,transform=transform)\n",
        "\n",
        "train_data_loader=DataLoader(dataset=train_dataset,\n",
        "                             batch_size=64,shuffle=True)\n",
        "test_data_loader=DataLoader(dataset=test_dataset,\n",
        "                            batch_size=64,shuffle=True)\n",
        "img,label=next(iter(train_data_loader))\n",
        "image = img[0].permute(1,2,0) * 0.5 + 0.5\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "print(image.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "rSkEptzx18tx",
        "outputId": "7c9f2300-ba9f-473c-e035-e3d34cb69b3a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 32, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [

      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVzuJz0Z-FJR",
        "outputId": "f34d8c05-2840-4246-a996-75bf4d726ed8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 512, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn,optim\n",
        "from torchvision import transforms,datasets\n",
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform=transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,),(0.5,))])\n",
        "\n",
        "train_dataset=datasets.CIFAR10(root='/content/drive/MyDrive/Colab Notebooks/celeba/data',\n",
        "                               train=True,download=False,transform=transform)\n",
        "test_dataset=datasets.CIFAR10(root='/content/drive/MyDrive/Colab Notebooks/celeba/data',\n",
        "                              train=False,download=False,transform=transform)\n",
        "\n",
        "train_data_loader=DataLoader(dataset=train_dataset,\n",
        "                             batch_size=64,shuffle=True)\n",
        "test_data_loader=DataLoader(dataset=test_dataset,\n",
        "                            batch_size=64,shuffle=True)\n",
        "\n",
        "class CNN_CIFAR10(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.SEQ=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3,out_channels=64,kernel_size=3,stride=1,padding=1),# out_size=3,64,32,32\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1),# out_size=3,64,32,32\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2,padding=0),# out_size=3,64,16,16\n",
        "\n",
        "        # nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1),# out_size=3,128,16,16\n",
        "        # nn.BatchNorm2d(128),\n",
        "        # nn.ReLU(),\n",
        "        # nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1),# out_size=3,128,16,16\n",
        "        # nn.BatchNorm2d(128),\n",
        "        # nn.ReLU(),\n",
        "        # nn.MaxPool2d(kernel_size=2,stride=2,padding=0),# out_size=3,128,8,8\n",
        "\n",
        "        # nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1),# out_size=3,256,8,8\n",
        "        # nn.BatchNorm2d(256),\n",
        "        # nn.ReLU(),\n",
        "        # nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1),# out_size=3,256,8,8\n",
        "        # nn.BatchNorm2d(256),\n",
        "        # nn.ReLU(),\n",
        "        # nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1),# out_size=3,256,8,8\n",
        "        # nn.BatchNorm2d(256),\n",
        "        # nn.ReLU(),\n",
        "        # nn.MaxPool2d(kernel_size=2,stride=2,padding=0),# out_size=3,256,4,4\n",
        "\n",
        "        # nn.Conv2d(in_channels=256,out_channels=512,kernel_size=3,stride=1,padding=1),# out_size=3,512,4,4\n",
        "        # nn.BatchNorm2d(512),\n",
        "        # nn.ReLU(),\n",
        "        # nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1),# out_size=3,512,4,4\n",
        "        # nn.BatchNorm2d(512),\n",
        "        # nn.ReLU(),\n",
        "        # nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1),# out_size=3,512,4,4\n",
        "        # nn.BatchNorm2d(512),\n",
        "        # nn.ReLU(),\n",
        "        # nn.MaxPool2d(kernel_size=2,stride=2,padding=0),# out_size=3,512,2,2\n",
        "\n",
        "        # nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1),# out_size=3,512,2,2\n",
        "        # nn.BatchNorm2d(512),\n",
        "        # nn.ReLU(),\n",
        "        # nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1),# out_size=3,512,2,2\n",
        "        # nn.BatchNorm2d(512),\n",
        "        # nn.ReLU(),\n",
        "        # nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1),# out_size=3,512,2,2\n",
        "        # nn.BatchNorm2d(512),\n",
        "        # nn.ReLU(),\n",
        "        # nn.MaxPool2d(kernel_size=2,stride=2,padding=0),# out_size=3,512,1,1\n",
        "    )\n",
        "    self.flaten=nn.Flatten()# out_size=512x1x1\n",
        "    self.fc=nn.Sequential(\n",
        "        nn.Linear(in_features=3*512,out_features=4096),\n",
        "        nn.ReLU(),nn.Dropout(0.5),\n",
        "        nn.Linear(in_features=4096,out_features=2048),\n",
        "        nn.ReLU(),nn.Dropout(0.5),\n",
        "        nn.Linear(in_features=2048,out_features=10))\n",
        "  def forward(self,x):\n",
        "    x=self.SEQ(x)\n",
        "    # x=self.flaten(x)\n",
        "    # x=self.fc(x)\n",
        "    return x\n",
        "\n",
        "x=torch.randn(3,3,32,32)\n",
        "model=CNN_CIFAR10()\n",
        "print(model(x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYodFqD99DkJ",
        "outputId": "01521281-3b07-47f8-b2f0-17981a2a99db"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 64, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn,optim\n",
        "from torchvision import transforms,datasets\n",
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform=transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,),(0.5,))])\n",
        "\n",
        "train_dataset=datasets.CIFAR10(root='/content/drive/MyDrive/Colab Notebooks/celeba/data',\n",
        "                               train=True,download=False,transform=transform)\n",
        "test_dataset=datasets.CIFAR10(root='/content/drive/MyDrive/Colab Notebooks/celeba/data',\n",
        "                              train=False,download=False,transform=transform)\n",
        "\n",
        "train_data_loader=DataLoader(dataset=train_dataset,\n",
        "                             batch_size=32,shuffle=True)\n",
        "test_data_loader=DataLoader(dataset=test_dataset,\n",
        "                            batch_size=32,shuffle=True)\n",
        "\n",
        "class CNN_CIFAR10(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.SEQ=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3,out_channels=64,kernel_size=3,stride=1,padding=1),# out_size=3,64,32,32\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1),# out_size=3,64,32,32\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2,padding=0),# out_size=3,64,16,16\n",
        "\n",
        "        nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1),# out_size=3,128,16,16\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1),# out_size=3,128,16,16\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2,padding=0),# out_size=3,128,8,8\n",
        "\n",
        "        nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1),# out_size=3,256,8,8\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1),# out_size=3,256,8,8\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1),# out_size=3,256,8,8\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2,padding=0),# out_size=3,256,4,4\n",
        "\n",
        "        nn.Conv2d(in_channels=256,out_channels=512,kernel_size=3,stride=1,padding=1),# out_size=3,512,4,4\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1),# out_size=3,512,4,4\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1),# out_size=3,512,4,4\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2,padding=0),# out_size=3,512,2,2\n",
        "\n",
        "        nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1),# out_size=3,512,2,2\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1),# out_size=3,512,2,2\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1),# out_size=3,512,2,2\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2,padding=0),# out_size=3,512,1,1\n",
        "    )\n",
        "    self.flaten=nn.Flatten()# out_size=512x1x1\n",
        "    self.fc=nn.Sequential(\n",
        "        nn.Linear(in_features=512,out_features=4096),\n",
        "        nn.ReLU(),nn.Dropout(0.5),\n",
        "        nn.Linear(in_features=4096,out_features=2048),\n",
        "        nn.ReLU(),nn.Dropout(0.5),\n",
        "        nn.Linear(in_features=2048,out_features=10))\n",
        "  def forward(self,x):\n",
        "    x=self.SEQ(x)\n",
        "    x=self.flaten(x)\n",
        "    x=self.fc(x)\n",
        "    return x\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model=CNN_CIFAR10().to(device)\n",
        "  num_epochs=10\n",
        "  criterion=nn.CrossEntropyLoss()\n",
        "  optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
        "  total_step=len(train_data_loader)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    loss_total=0\n",
        "    for images,labels in train_data_loader:\n",
        "      images=images.to(device)\n",
        "      labels=labels.to(device)\n",
        "      outputs=model(images)\n",
        "      loss=criterion(outputs,labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_total+=loss.item()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}; Loss: {loss_total/total_step:.4f}\")\n",
        "  torch.save(model.state_dict(),\"/content/drive/MyDrive/Colab Notebooks/celeba/CNN_CIFAR10_10epochs.pth\")\n",
        "  model.eval()\n",
        "\n",
        "  correct=0\n",
        "  total=0\n",
        "  with torch.no_grad():\n",
        "      for image,label in test_data_loader:\n",
        "          image,label=image.to(device),label.to(device)\n",
        "          outputs=model(image)\n",
        "          _,predicted=torch.max(outputs,1)\n",
        "          total+=label.size(0)\n",
        "          correct+=(predicted==label).sum().item()\n",
        "  accuracy=100*correct/total\n",
        "  print(\"độ chính xác trên bộ test: \",accuracy)\n",
        "\n",
        "\n",
        "  model.eval()\n",
        "  dataiter = iter(test_data_loader)\n",
        "  images, labels = next(dataiter)\n",
        "  images, labels = images[:10].to(device), labels[:10].to(device)\n",
        "  with torch.no_grad():\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "  images = images.cpu().numpy()\n",
        "  images = images * 0.5 + 0.5\n",
        "  images = np.transpose(images, (0, 2, 3, 1))\n",
        "\n",
        "\n",
        "  classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "            'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "  # Hiển thị 10 ảnh cùng với nhãn dự đoán\n",
        "  fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "  fig.suptitle(\"Predictions from CNN Model on CIFAR-10\", fontsize=16)\n",
        "\n",
        "  for i, ax in enumerate(axes.flat):\n",
        "      ax.imshow(images[i])\n",
        "      ax.set_title(f\"Pred: {classes[predicted[i]]}\\nTrue: {classes[labels[i]]}\", fontsize=10)\n",
        "      ax.axis('off')\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca2qBCoGy8iv",
        "outputId": "9d5efbcc-68b8-4488-88d7-d9c8d8a2aad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1; Loss: 1.9688\n",
            "Epoch: 2; Loss: 1.6806\n",
            "Epoch: 3; Loss: 1.4142\n",
            "Epoch: 4; Loss: 1.1328\n",
            "Epoch: 5; Loss: 0.9420\n"
          ]
        }
      ]
    }
  ]
}
